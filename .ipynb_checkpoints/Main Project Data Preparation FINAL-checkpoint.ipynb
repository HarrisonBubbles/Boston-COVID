{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TSucw_dNO6rT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import censusdata\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4_-xokXO6rW"
   },
   "source": [
    "## Get COVID Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jV2d159sO6rX"
   },
   "source": [
    "First we read CSVs for Boston, NYC, and Virginia Beach positivity rates. We collected the Boston data manually from the Boston Public Health Commission website and constructed a CSV. We retrieved the Virginia Beach dataset CSV from the Virginia Department of Public Health. We pull the NYC data directly from the New York City Department of Health and Mental Hygiene's GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "414T8vygO6rX"
   },
   "outputs": [],
   "source": [
    "boston_data = pd.read_csv(\"CSVs/boston_zipcode_positive.csv\", dtype={'zipcode':'str', 'positive_rate':'float64'})\n",
    "nyc_data = pd.read_csv('https://raw.githubusercontent.com/nychealth/coronavirus-data/master/totals/data-by-modzcta.csv')\n",
    "vb_data = pd.read_csv('CSVs/VDH-COVID-19-PublicUseDataset-ZIPCode.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTLQUAyQO6rX"
   },
   "source": [
    "The Virginia dataset includes cumulative COVID-19 numbers at difference points of time for every zip code in Virgnia. We filter the dataset down to the data with the most report date. We also create a list of zip codes that are in Virginia Beach, and use this list to filter the data down to only include zip codes that are actually in Virginia Beach.\n",
    "\n",
    "We also construct a column for cumulative positivity rate (positive_rate). We divide the total number of cases (Number of Cases) by total number of tests (Number of PCR Testing Encounters). Finally, we rename the ZIP Code column as zipcode and filter the dataset to only include the zipcode and positive_rate columns. This dataset's columns and columns match with the dataset for Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xYxgPrtzO6rX"
   },
   "outputs": [],
   "source": [
    "# Prepare Virginia Beach data\n",
    "# List of Virginia Beach zip codes\n",
    "vb_zips = ['23450', '23451', '23452', '23453', '23454', '23455', '23456', '23457', '23458', '23459',\n",
    "           '23460', '23461', '23462', '23463', '23464', '23465', '23466', '23467', '23471', '23479']\n",
    "\n",
    "vb_data = vb_data[vb_data['Report Date']=='04/17/2021']\n",
    "vb_data = vb_data[vb_data['ZIP Code'].isin(vb_zips)]\n",
    "vb_data['positive_rate'] = vb_data['Number of Cases'].astype(float) / vb_data['Number of PCR Testing Encounters'].astype(float)\n",
    "\n",
    "vb_data.rename(columns={'Number of PCR Testing Encounters':'number_tests'}, inplace=True)\n",
    "vb_data['number_tests'] = vb_data['number_tests'].astype(int)\n",
    "\n",
    "vb_data.rename(columns={'ZIP Code':'zipcode'}, inplace=True)\n",
    "vb_data = vb_data[['zipcode', 'positive_rate', 'number_tests']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7K1O9mQO6rX"
   },
   "source": [
    "The NYC data has a data for each Modified ZCTA. A column called \"label\" lists the zip codes in the Modified ZCTA area. We need the zip codes so we can aggregate them into neighborhoods later, so first split the \"label\" column by \", \" so its elements are actually lists of zip codes (rather than just strings that look like lists), and expand the dataset using the \"explode\" function so there is a row for each zip code. The dataset already has a column for cumulative positivity rate (\"PERCENT_POSITIVE\"), but we divide it by 100 and create a new column called \"positive_rate\" so it is in decimal form. Finally, as before, we rename the \"label\" column to \"zipcode\" and filter the dataset down to only include the \"zipcode\" and \"positive_rate\" columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pW2bxXAPO6rY"
   },
   "outputs": [],
   "source": [
    "# Prepare NYC data\n",
    "# NYC data is organized by MODIFIED_ZCTA. Expload on 'label' column which is has zipcodes in MODIFIED_ZCTA and rename\n",
    "nyc_data['label'] = nyc_data['label'].str.split(', ')\n",
    "nyc_data = nyc_data.explode('label')\n",
    "# Positive rate in decimal form\n",
    "nyc_data['positive_rate'] = nyc_data['PERCENT_POSITIVE']/100\n",
    "nyc_data.rename(columns={'TOTAL_COVID_TESTS':'number_tests'}, inplace=True)\n",
    "nyc_data.rename(columns={'label':'zipcode'}, inplace=True)\n",
    "nyc_data = nyc_data[['zipcode', 'positive_rate', 'number_tests']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO5W5hYgO6rY"
   },
   "source": [
    "## Get Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRin3M_NO6rY"
   },
   "source": [
    "We retreive census data using the CensusData package from PyPi (https://pypi.org/project/CensusData/) that accesses the U.S. Census Bureau's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tkmCgKHdO6rY",
    "outputId": "be66513a-9397-4388-cd89-a1b7a89ce725",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable     | Table                          | Label                                                    | Type \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "B19013_001E  | MEDIAN HOUSEHOLD INCOME IN THE | !! Estimate Median household income in the past 12 month | int  \n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Finds census variables\n",
    "censusdata.printtable(censusdata.censustable('acs5', 2019, 'B19013'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lwupLRWO6rY"
   },
   "source": [
    "We find the numerical identifiers assigned to Massachusetts, New York, and Virginia in order to pull data for those states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SWs-InjMO6rZ",
    "outputId": "541fcb41-f264-4600-97ee-bcf39b8deed4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary level: 040, state:25\n",
      "Summary level: 040, state:36\n",
      "Summary level: 040, state:51\n"
     ]
    }
   ],
   "source": [
    "states = censusdata.geographies(censusdata.censusgeo([('state', '*')]), 'acs5', 2019)\n",
    "\n",
    "# find Massachusetts, New York, and Missouri\n",
    "print(states['Massachusetts'])\n",
    "print(states['New York'])\n",
    "print(states['Virginia'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57XpAeINO6rZ"
   },
   "source": [
    "We create a DataFrame that with racial demographics data for each zip code tabulation area in Massachusetts, a DataFrame with wealth demographics data for each ZCTA, and a DataFrame with data on the means of transportation to work for each ZCTA. We do the same for New York and Virginia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x1Otkfz1O6rZ"
   },
   "outputs": [],
   "source": [
    "# create race df for Massachusetts\n",
    "ma_race = censusdata.download('acs5', 2019,\n",
    "               censusdata.censusgeo([('state', '25'),\n",
    "                             ('zip code tabulation area', '*')]),\n",
    "              ['B03002_001E', 'B03002_002E', 'B03002_003E',\n",
    "               'B03002_004E', 'B03002_005E',\n",
    "               'B03002_006E', 'B03002_007E',\n",
    "               'B03002_008E', 'B03002_009E',\n",
    "               'B03002_010E', 'B03002_011E',\n",
    "               'B03002_012E', 'B03002_013E',\n",
    "               'B03002_014E', 'B03002_015E',\n",
    "               'B03002_016E', 'B03002_017E',\n",
    "               'B03002_018E', 'B03002_019E',\n",
    "               'B03002_020E', 'B03002_021E', 'B01003_001E'])\n",
    "\n",
    "# create income/poverty level ratio df for MA\n",
    "# Also includes variable for Aggregate Public Assistance and Median Household Income\n",
    "ma_poverty = censusdata.download('acs5', 2019,\n",
    "               censusdata.censusgeo([('state', '25'),\n",
    "                             ('zip code tabulation area', '*')]),\n",
    "              ['C17002_001E', 'C17002_002E', 'C17002_003E',\n",
    "               'C17002_004E', 'C17002_005E', 'C17002_006E',\n",
    "               'C17002_007E', 'C17002_008E', 'B19067_001E', 'B19013_001E'])\n",
    "\n",
    "# create transportation df for MA\n",
    "ma_transport = censusdata.download('acs5', 2019,\n",
    "               censusdata.censusgeo([('state', '25'),\n",
    "                             ('zip code tabulation area', '*')]),\n",
    "              ['B08128_001E', 'B08128_011E', 'B08128_021E',\n",
    "               'B08128_031E', 'B08128_041E', 'B08128_051E',\n",
    "               'B08128_061E'])\n",
    "\n",
    "# create race df for NY\n",
    "ny_race = censusdata.download('acs5', 2019,\n",
    "               censusdata.censusgeo([('state', '36'),\n",
    "                             ('zip code tabulation area', '*')]),\n",
    "              ['B03002_001E', 'B03002_002E', 'B03002_003E',\n",
    "               'B03002_004E', 'B03002_005E',\n",
    "               'B03002_006E', 'B03002_007E',\n",
    "               'B03002_008E', 'B03002_009E',\n",
    "               'B03002_010E', 'B03002_011E',\n",
    "               'B03002_012E', 'B03002_013E',\n",
    "               'B03002_014E', 'B03002_015E',\n",
    "               'B03002_016E', 'B03002_017E',\n",
    "               'B03002_018E', 'B03002_019E',\n",
    "               'B03002_020E', 'B03002_021E', 'B01003_001E'])\n",
    "\n",
    "# create income/poverty ratio df for NY\n",
    "ny_poverty = censusdata.download('acs5', 2019,\n",
    "               censusdata.censusgeo([('state', '36'),\n",
    "                             ('zip code tabulation area', '*')]),\n",
    "              ['C17002_001E', 'C17002_002E', 'C17002_003E',\n",
    "               'C17002_004E', 'C17002_005E', 'C17002_006E',\n",
    "               'C17002_007E', 'C17002_008E', 'B19067_001E', 'B19013_001E'])\n",
    "\n",
    "# create transportation df for NY\n",
    "ny_transport = censusdata.download('acs5', 2019,\n",
    "               censusdata.censusgeo([('state', '36'),\n",
    "                             ('zip code tabulation area', '*')]),\n",
    "              ['B08128_001E', 'B08128_011E', 'B08128_021E',\n",
    "               'B08128_031E', 'B08128_041E', 'B08128_051E',\n",
    "               'B08128_061E'])\n",
    "\n",
    "# create race df for VA\n",
    "va_race = censusdata.download('acs5', 2019,\n",
    "               censusdata.censusgeo([('state', '51'),\n",
    "                             ('zip code tabulation area', '*')]),\n",
    "              ['B03002_001E', 'B03002_002E', 'B03002_003E',\n",
    "               'B03002_004E', 'B03002_005E',\n",
    "               'B03002_006E', 'B03002_007E',\n",
    "               'B03002_008E', 'B03002_009E',\n",
    "               'B03002_010E', 'B03002_011E',\n",
    "               'B03002_012E', 'B03002_013E',\n",
    "               'B03002_014E', 'B03002_015E',\n",
    "               'B03002_016E', 'B03002_017E',\n",
    "               'B03002_018E', 'B03002_019E',\n",
    "               'B03002_020E', 'B03002_021E', 'B01003_001E'])\n",
    "\n",
    "# create income/poverty ratio df for VA\n",
    "va_poverty = censusdata.download('acs5', 2019,\n",
    "               censusdata.censusgeo([('state', '51'),\n",
    "                             ('zip code tabulation area', '*')]),\n",
    "              ['C17002_001E', 'C17002_002E', 'C17002_003E',\n",
    "               'C17002_004E', 'C17002_005E', 'C17002_006E',\n",
    "               'C17002_007E', 'C17002_008E', 'B19067_001E', 'B19013_001E'])\n",
    "\n",
    "# create transportation df for VA\n",
    "va_transport = censusdata.download('acs5', 2019,\n",
    "               censusdata.censusgeo([('state', '51'),\n",
    "                             ('zip code tabulation area', '*')]),\n",
    "              ['B08128_001E', 'B08128_011E', 'B08128_021E',\n",
    "               'B08128_031E', 'B08128_041E', 'B08128_051E',\n",
    "               'B08128_061E'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKqDyuydO6rb"
   },
   "source": [
    "We rename the column names in each DataFrame so they are more descriptive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Fn7U4NyTO6rb"
   },
   "outputs": [],
   "source": [
    "# change labels\n",
    "ma_race = ma_race.rename(columns={'B03002_001E' : 'Race Total', 'B03002_002E' : 'Total, not Hispanic/Latino', \n",
    "                                       'B03002_003E' : 'White, not Hispanic/Latino',\n",
    "               'B03002_004E' : 'Black, not Hispanic/Latino', 'B03002_005E' : 'Native, not Hispanic/Latino',\n",
    "               'B03002_006E' : 'Asian, not Hispanic/Latino', 'B03002_007E' : 'PI, not Hispanic/Latino',\n",
    "               'B03002_008E' : 'Other, not Hispanic/Latino', 'B03002_009E' : '2+, not Hispanic/Latino',\n",
    "               'B03002_010E' : '2+, not Hispanic/Latino, incl. Other', 'B03002_011E' : '2+, not Hispanic/Latino, excl. Other',\n",
    "               'B03002_012E' : 'Total, Hispanic/Latino', 'B03002_013E' : 'White, Hispanic/Latino',\n",
    "               'B03002_014E' : 'Black, Hispanic/Latino', 'B03002_015E' : 'Native, Hispanic/Latino',\n",
    "               'B03002_016E' : 'Asian, Hispanic/Latino', 'B03002_017E' : 'PI, Hispanic/Latino',\n",
    "               'B03002_018E' : 'Other, Hispanic/Latino', 'B03002_019E' : '2+, Hispanic/Latino',\n",
    "               'B03002_020E' : '2+, Hispanic/Latino, incl. Other', 'B03002_021E' : '2+, Hispanic/Latino, excl. Other',\n",
    "               'B01003_001E' : 'Total Population'})\n",
    "ny_race = ny_race.rename(columns={'B03002_001E' : 'Race Total', 'B03002_002E' : 'Total, not Hispanic/Latino', \n",
    "                                       'B03002_003E' : 'White, not Hispanic/Latino',\n",
    "               'B03002_004E' : 'Black, not Hispanic/Latino', 'B03002_005E' : 'Native, not Hispanic/Latino',\n",
    "               'B03002_006E' : 'Asian, not Hispanic/Latino', 'B03002_007E' : 'PI, not Hispanic/Latino',\n",
    "               'B03002_008E' : 'Other, not Hispanic/Latino', 'B03002_009E' : '2+, not Hispanic/Latino',\n",
    "               'B03002_010E' : '2+, not Hispanic/Latino, incl. Other', 'B03002_011E' : '2+, not Hispanic/Latino, excl. Other',\n",
    "               'B03002_012E' : 'Total, Hispanic/Latino', 'B03002_013E' : 'White, Hispanic/Latino',\n",
    "               'B03002_014E' : 'Black, Hispanic/Latino', 'B03002_015E' : 'Native, Hispanic/Latino',\n",
    "               'B03002_016E' : 'Asian, Hispanic/Latino', 'B03002_017E' : 'PI, Hispanic/Latino',\n",
    "               'B03002_018E' : 'Other, Hispanic/Latino', 'B03002_019E' : '2+, Hispanic/Latino',\n",
    "               'B03002_020E' : '2+, Hispanic/Latino, incl. Other', 'B03002_021E' : '2+, Hispanic/Latino, excl. Other',\n",
    "               'B01003_001E' : 'Total Population'})\n",
    "va_race = va_race.rename(columns={'B03002_001E' : 'Race Total', 'B03002_002E' : 'Total, not Hispanic/Latino', \n",
    "                                       'B03002_003E' : 'White, not Hispanic/Latino',\n",
    "               'B03002_004E' : 'Black, not Hispanic/Latino', 'B03002_005E' : 'Native, not Hispanic/Latino',\n",
    "               'B03002_006E' : 'Asian, not Hispanic/Latino', 'B03002_007E' : 'PI, not Hispanic/Latino',\n",
    "               'B03002_008E' : 'Other, not Hispanic/Latino', 'B03002_009E' : '2+, not Hispanic/Latino',\n",
    "               'B03002_010E' : '2+, not Hispanic/Latino, incl. Other', 'B03002_011E' : '2+, not Hispanic/Latino, excl. Other',\n",
    "               'B03002_012E' : 'Total, Hispanic/Latino', 'B03002_013E' : 'White, Hispanic/Latino',\n",
    "               'B03002_014E' : 'Black, Hispanic/Latino', 'B03002_015E' : 'Native, Hispanic/Latino',\n",
    "               'B03002_016E' : 'Asian, Hispanic/Latino', 'B03002_017E' : 'PI, Hispanic/Latino',\n",
    "               'B03002_018E' : 'Other, Hispanic/Latino', 'B03002_019E' : '2+, Hispanic/Latino',\n",
    "               'B03002_020E' : '2+, Hispanic/Latino, incl. Other', 'B03002_021E' : '2+, Hispanic/Latino, excl. Other',\n",
    "               'B01003_001E' : 'Total Population'})\n",
    "\n",
    "#\n",
    "ma_poverty = ma_poverty.rename(columns={'C17002_001E' : 'Poverty Total', 'C17002_002E' : 'Under .50', 'C17002_003E' : '.50 to .99',\n",
    "               'C17002_004E' : '1.00 to 1.24', 'C17002_005E' : '1.25 to 1.49', 'C17002_006E' : '1.50 to 1.84',\n",
    "               'C17002_007E' : '1.84 to 1.99', 'C17002_008E' : 'Over 2.00', 'B19067_001E' : 'Agg Public Assistance',\n",
    "               'B19013_001E' : 'Median Family Income'})\n",
    "ny_poverty = ny_poverty.rename(columns={'C17002_001E' : 'Poverty Total', 'C17002_002E' : 'Under .50', 'C17002_003E' : '.50 to .99',\n",
    "               'C17002_004E' : '1.00 to 1.24', 'C17002_005E' : '1.25 to 1.49', 'C17002_006E' : '1.50 to 1.84',\n",
    "               'C17002_007E' : '1.84 to 1.99', 'C17002_008E' : 'Over 2.00', 'B19067_001E' : 'Agg Public Assistance',\n",
    "               'B19013_001E' : 'Median Family Income'})\n",
    "va_poverty = va_poverty.rename(columns={'C17002_001E' : 'Poverty Total', 'C17002_002E' : 'Under .50', 'C17002_003E' : '.50 to .99',\n",
    "               'C17002_004E' : '1.00 to 1.24', 'C17002_005E' : '1.25 to 1.49', 'C17002_006E' : '1.50 to 1.84',\n",
    "               'C17002_007E' : '1.84 to 1.99', 'C17002_008E' : 'Over 2.00', 'B19067_001E' : 'Agg Public Assistance',\n",
    "               'B19013_001E' : 'Median Family Income'})\n",
    "\n",
    "#\n",
    "ma_transport = ma_transport.rename(columns={'B08128_001E' : 'Transport Total', 'B08128_011E' : 'Car/Truck/Van, alone', \n",
    "                                            'B08128_021E' : 'Car/Truck/Van, carpool', 'B08128_031E' : 'Public Transport, no taxi',\n",
    "                                            'B08128_041E' : 'Walk', 'B08128_051E' : 'Taxi, Motorcycle, Bike, or Other', \n",
    "                                            'B08128_061E' : 'Work from home'})\n",
    "ny_transport = ny_transport.rename(columns={'B08128_001E' : 'Transport Total', 'B08128_011E' : 'Car/Truck/Van, alone', \n",
    "                                            'B08128_021E' : 'Car/Truck/Van, carpool', 'B08128_031E' : 'Public Transport, no taxi',\n",
    "                                            'B08128_041E' : 'Walk', 'B08128_051E' : 'Taxi, Motorcycle, Bike, or Other', \n",
    "                                            'B08128_061E' : 'Work from home'})\n",
    "va_transport = va_transport.rename(columns={'B08128_001E' : 'Transport Total', 'B08128_011E' : 'Car/Truck/Van, alone', \n",
    "                                            'B08128_021E' : 'Car/Truck/Van, carpool', 'B08128_031E' : 'Public Transport, no taxi',\n",
    "                                            'B08128_041E' : 'Walk', 'B08128_051E' : 'Taxi, Motorcycle, Bike, or Other', \n",
    "                                            'B08128_061E' : 'Work from home'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFFHwMYnO6rc"
   },
   "source": [
    "For each DataFrame we create a \"zipcode\" column. We do this by extracting the zip code from the index of each DataFrame using a lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4_kY20IGO6rd"
   },
   "outputs": [],
   "source": [
    "ma_race['zipcode'] = ma_race.index.map(lambda x: x.params()[1][1]).to_list()\n",
    "ny_race['zipcode'] = ny_race.index.map(lambda x: x.params()[1][1]).to_list()\n",
    "va_race['zipcode'] = va_race.index.map(lambda x: x.params()[1][1]).to_list()\n",
    "ma_poverty['zipcode'] = ma_poverty.index.map(lambda x: x.params()[1][1]).to_list()\n",
    "ny_poverty['zipcode'] = ny_poverty.index.map(lambda x: x.params()[1][1]).to_list()\n",
    "va_poverty['zipcode'] = va_poverty.index.map(lambda x: x.params()[1][1]).to_list()\n",
    "ma_transport['zipcode'] = ma_transport.index.map(lambda x: x.params()[1][1]).to_list()\n",
    "ny_transport['zipcode'] = ny_transport.index.map(lambda x: x.params()[1][1]).to_list()\n",
    "va_transport['zipcode'] = va_transport.index.map(lambda x: x.params()[1][1]).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpj87RccO6re"
   },
   "source": [
    "## Merge Datasets and Aggregate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqc26uCNO6re"
   },
   "source": [
    "We merge the 3 census DataFrames with the COVID-19 DataFrame on zip code for each state/city. We do left joins, as this allows us to only include the zip codes in a state's census DataFrames that are in a city's COVID DataFrame (so we only include data for NYC zip codes, not data for all of New York, for example). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "icXgkOmLO6re"
   },
   "outputs": [],
   "source": [
    "# Merge data\n",
    "boston_merged = boston_data.merge(ma_race, how='left', on='zipcode')\n",
    "boston_merged = boston_merged.merge(ma_poverty, how='left', on='zipcode')\n",
    "boston_merged = boston_merged.merge(ma_transport, how='left', on='zipcode')\n",
    "\n",
    "nyc_merged = nyc_data.merge(ny_race, how='left', on='zipcode')\n",
    "nyc_merged = nyc_merged.merge(ny_poverty, how='left', on='zipcode')\n",
    "nyc_merged = nyc_merged.merge(ny_transport, how='left', on='zipcode')\n",
    "\n",
    "vb_merged = vb_data.merge(va_race, how='left', on='zipcode')\n",
    "vb_merged = vb_merged.merge(va_poverty, how='left', on='zipcode')\n",
    "vb_merged = vb_merged.merge(va_transport, how='left', on='zipcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4BaJeF-O6re"
   },
   "source": [
    "We read an excel file we constructed that has a column for each zip code in each of the three city's, and another for the neighborhood a zip code is in. We then transform this to a dictionary with the keys being zip codes and the values being neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Lx01PlgDO6re"
   },
   "outputs": [],
   "source": [
    "zipcode_neighborhood_map = pd.read_excel('CSVs/zipcode_neighborhood_map.xlsx', dtype={'zipcode':'str'})\n",
    "zn_dict = zipcode_neighborhood_map.set_index('zipcode').T.to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdNjuQfVO6re"
   },
   "source": [
    "We next create a \"neighborhood\" field in each city's DataFrame that maps zip code to the neighborhood the zip code is in using the dictionary previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "16I29ZMwO6re"
   },
   "outputs": [],
   "source": [
    "boston_merged['neighborhood'] = boston_merged['zipcode'].map(zn_dict)\n",
    "nyc_merged['neighborhood'] = nyc_merged['zipcode'].map(zn_dict)\n",
    "vb_merged['neighborhood'] = vb_merged['zipcode'].map(zn_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyu5a7_tO6re"
   },
   "source": [
    "We read a CSV that contains population density numbers for each zip code in the U.S. Afterwards we realized that we needed population densities for each neighborhood, not just each zip code, so we just created an \"area\" column by multiplying the population and population densities for each zip code. We created a dictionary that maps each zipcode to its geographical area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CzmKFy-SO6re"
   },
   "outputs": [],
   "source": [
    "popdens = pd.read_csv('CSVs/uszips.csv', usecols=['zip','population','density'])\n",
    "popdens['zipcode'] = popdens['zip'].map(str).str.zfill(5) # Add leading zeros so the zipcode length is 5.\n",
    "popdens['area'] = popdens['population']/popdens['density']\n",
    "area_dict = popdens[['zipcode','area']].set_index('zipcode').T.to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d55OL04TO6re"
   },
   "source": [
    "We create an \"area\" field in each city's DataFrame that maps zip code to the geographical area the zip code covers using the dictionary previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MK-P95J-O6re"
   },
   "outputs": [],
   "source": [
    "boston_merged['area'] = boston_merged['zipcode'].map(area_dict)\n",
    "nyc_merged['area'] = nyc_merged['zipcode'].map(area_dict)\n",
    "vb_merged['area'] = vb_merged['zipcode'].map(area_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-h_M2qwO6re"
   },
   "source": [
    "Some fields contain the value -666666666.0. We replace these nonsensical (or missing) values with np.nan so they don't distort our calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3pqUipuqO6rf"
   },
   "outputs": [],
   "source": [
    "boston_merged.replace(-666666666.0, np.nan, inplace=True)\n",
    "nyc_merged.replace(-666666666.0, np.nan, inplace=True)\n",
    "vb_merged.replace(-666666666.0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7Je9lhDGO6rf"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoIE-1PfO6rf"
   },
   "source": [
    "Now we aggregate the zip code level data, grouped by neighborhood. For positive_rate and Median Family Income we take the aggregate mean weighted by population. For all the other variables, which are already total values, we take the aggregate sums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pS0THrLrO6rf"
   },
   "outputs": [],
   "source": [
    "# positive_rate should be mean weighted by population\n",
    "# Median Family Income should be mean weighted by population\n",
    "# Everything else should be aggregate sum\n",
    "\n",
    "# Boston\n",
    "boston_aggs = boston_merged.loc[:, ~boston_merged.columns.isin(['zipcode', 'positive_rate', 'Median Family Income'])].groupby('neighborhood').sum()\n",
    "boston_aggs_2 = boston_merged.groupby('neighborhood').apply(lambda df: (df['Median Family Income'] * df['Total Population']).sum() / df['Total Population'].sum())\n",
    "boston_aggs_3 = boston_merged.groupby('neighborhood').apply(lambda df: (df['positive_rate'] * df['Total Population']).sum() / df['Total Population'].sum())\n",
    "boston_aggs['Median Family Income'] = boston_aggs_2\n",
    "boston_aggs['positive_rate'] = boston_aggs_3\n",
    "\n",
    "# NYC\n",
    "nyc_aggs = nyc_merged.loc[:, ~nyc_merged.columns.isin(['zipcode', 'positive_rate', 'Median Family Income'])].groupby('neighborhood').sum()\n",
    "nyc_aggs_2 = nyc_merged.groupby('neighborhood').apply(lambda df: (df['Median Family Income'] * df['Total Population']).sum() / df['Total Population'].sum())\n",
    "nyc_aggs_3 = nyc_merged.groupby('neighborhood').apply(lambda df: (df['positive_rate'] * df['Total Population']).sum() / df['Total Population'].sum())\n",
    "nyc_aggs['Median Family Income'] = nyc_aggs_2\n",
    "nyc_aggs['positive_rate'] = nyc_aggs_3\n",
    "\n",
    "# Virginia Beach\n",
    "vb_aggs = vb_merged.loc[:, ~vb_merged.columns.isin(['zipcode', 'positive_rate', 'Median Family Income'])].groupby('neighborhood').sum()\n",
    "vb_aggs_2 = vb_merged.groupby('neighborhood').apply(lambda df: (df['Median Family Income'] * df['Total Population']).sum() / df['Total Population'].sum())\n",
    "vb_aggs_3 = vb_merged.groupby('neighborhood').apply(lambda df: (df['positive_rate'] * df['Total Population']).sum() / df['Total Population'].sum())\n",
    "vb_aggs['Median Family Income'] = vb_aggs_2\n",
    "vb_aggs['positive_rate'] = vb_aggs_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIfp0IssO6rf"
   },
   "source": [
    "We merge the aggregate data with the zip codes and neighborhood fields from the previously merged datasets on the \"neighborhood\" column. By doing this, we are filling in values for each zip code with the neighborhood level aggregates. We do this beacuse when we construct our city maps later, we need values for each zip code boundary, even though, although the values are the same for zip codes in the same neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jiUsPJhfO6rf"
   },
   "outputs": [],
   "source": [
    "# Merge such that there is a row for each zipcode, but zipcodes in the same neighborhood have the same data\n",
    "# Doing this for mapping purposes later\n",
    "boston_neighborhood_data = boston_merged[['zipcode','neighborhood']].merge(boston_aggs, on='neighborhood')\n",
    "nyc_neighborhood_data = nyc_merged[['zipcode','neighborhood']].merge(nyc_aggs, on='neighborhood')\n",
    "vb_neighborhood_data = vb_merged[['zipcode','neighborhood']].merge(vb_aggs, on='neighborhood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjK52Q7OO6rf"
   },
   "source": [
    "We change the racial demographics data so they are percentages of total population, not just the total number of people in some demographic in a neighborhood. We do this so the fields are comparable between different neighborhoods. We do the same thing for data of the number of people with income/poverty level ratios of some level, and the number of people with some means of transporting to work. We also create a column for population density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eKeYrjLDO6rf"
   },
   "outputs": [],
   "source": [
    "# Make race as percent of total population\n",
    "boston_neighborhood_data.loc[:,'Total, not Hispanic/Latino':'2+, Hispanic/Latino, excl. Other'] = boston_neighborhood_data.loc[:,'Total, not Hispanic/Latino':'2+, Hispanic/Latino, excl. Other'].div(boston_neighborhood_data.loc[:,'Race Total'], axis=0)\n",
    "nyc_neighborhood_data.loc[:,'Total, not Hispanic/Latino':'2+, Hispanic/Latino, excl. Other'] = nyc_neighborhood_data.loc[:,'Total, not Hispanic/Latino':'2+, Hispanic/Latino, excl. Other'].div(nyc_neighborhood_data.loc[:,'Race Total'], axis=0)\n",
    "vb_neighborhood_data.loc[:,'Total, not Hispanic/Latino':'2+, Hispanic/Latino, excl. Other'] = vb_neighborhood_data.loc[:,'Total, not Hispanic/Latino':'2+, Hispanic/Latino, excl. Other'].div(vb_neighborhood_data.loc[:,'Race Total'], axis=0)\n",
    "\n",
    "# Make poverty numbers into percent\n",
    "boston_neighborhood_data.loc[:,'Under .50':'Over 2.00'] = boston_neighborhood_data.loc[:,'Under .50':'Over 2.00'].div(boston_neighborhood_data.loc[:,'Poverty Total'], axis=0)\n",
    "nyc_neighborhood_data.loc[:,'Under .50':'Over 2.00'] = nyc_neighborhood_data.loc[:,'Under .50':'Over 2.00'].div(nyc_neighborhood_data.loc[:,'Poverty Total'], axis=0)\n",
    "vb_neighborhood_data.loc[:,'Under .50':'Over 2.00'] = vb_neighborhood_data.loc[:,'Under .50':'Over 2.00'].div(vb_neighborhood_data.loc[:,'Poverty Total'], axis=0)\n",
    "\n",
    "# Make transportation numbers into percent\n",
    "boston_neighborhood_data.loc[:, 'Car/Truck/Van, alone':'Work from home'] = boston_neighborhood_data.loc[:, 'Car/Truck/Van, alone':'Work from home'].div(boston_neighborhood_data.loc[:,'Transport Total'], axis=0)\n",
    "nyc_neighborhood_data.loc[:, 'Car/Truck/Van, alone':'Work from home'] = nyc_neighborhood_data.loc[:, 'Car/Truck/Van, alone':'Work from home'].div(nyc_neighborhood_data.loc[:,'Transport Total'], axis=0)\n",
    "vb_neighborhood_data.loc[:, 'Car/Truck/Van, alone':'Work from home'] = vb_neighborhood_data.loc[:, 'Car/Truck/Van, alone':'Work from home'].div(vb_neighborhood_data.loc[:,'Transport Total'], axis=0)\n",
    "\n",
    "# Calculate population density\n",
    "boston_neighborhood_data['Population Density'] = boston_neighborhood_data['Total Population']/boston_neighborhood_data['area']\n",
    "nyc_neighborhood_data['Population Density'] = nyc_neighborhood_data['Total Population']/nyc_neighborhood_data['area']\n",
    "vb_neighborhood_data['Population Density'] = vb_neighborhood_data['Total Population']/vb_neighborhood_data['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1T2ooLkoO6rf"
   },
   "source": [
    "We create a column for the percentage of the population with income/poverty level ratios below 2.00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aSdZ1nt6O6rf"
   },
   "outputs": [],
   "source": [
    "vb_neighborhood_data['Under 2.00'] = vb_neighborhood_data.loc[:,'Under .50':'1.84 to 1.99'].sum(axis=1)\n",
    "boston_neighborhood_data['Under 2.00'] = boston_neighborhood_data.loc[:,'Under .50':'1.84 to 1.99'].sum(axis=1)\n",
    "nyc_neighborhood_data['Under 2.00'] = nyc_neighborhood_data.loc[:,'Under .50':'1.84 to 1.99'].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31SkotPeO6rf"
   },
   "source": [
    "We create a column \"Car/Truck/Van\" that includes both people who transport alone and carpool using these means. We made this choice after our analysis discovered that both of these fields had very similar relationships to positivity rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UxOUMc7mO6rf"
   },
   "outputs": [],
   "source": [
    "vb_neighborhood_data['Car/Truck/Van'] = vb_neighborhood_data['Car/Truck/Van, alone'] + vb_neighborhood_data['Car/Truck/Van, carpool']\n",
    "boston_neighborhood_data['Car/Truck/Van'] = boston_neighborhood_data['Car/Truck/Van, alone'] + boston_neighborhood_data['Car/Truck/Van, carpool']\n",
    "nyc_neighborhood_data['Car/Truck/Van'] = nyc_neighborhood_data['Car/Truck/Van, alone'] + nyc_neighborhood_data['Car/Truck/Van, carpool']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuVRaqteXRBh"
   },
   "source": [
    "In the last few days before the project deadline we decided to add data for number of tests as well (or initial city dataframes only included positivity rates). We construct a variable \"test_rate\", which is the number of tests divided by the total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "eQ6l9MCWXQkX"
   },
   "outputs": [],
   "source": [
    "boston_neighborhood_data['test_rate'] = boston_neighborhood_data['number_tests']/boston_neighborhood_data['Total Population']\n",
    "nyc_neighborhood_data['test_rate'] = nyc_neighborhood_data['number_tests']/nyc_neighborhood_data['Total Population']\n",
    "vb_neighborhood_data['test_rate'] = vb_neighborhood_data['number_tests']/vb_neighborhood_data['Total Population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyFOl4keO6rf"
   },
   "source": [
    "We write the datasets we constructed to CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-mT67zrO6rg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nyc_neighborhood_data.to_csv('nyc_neighborhood_data.csv')\n",
    "boston_neighborhood_data.to_csv('boston_neighborhood_data.csv')\n",
    "vb_neighborhood_data.to_csv('vb_neighborhood_data.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Main Project Data Preparation FINAL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
